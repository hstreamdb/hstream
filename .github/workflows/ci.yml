name: ci

on:
  push:
    branches: [main, master]

  pull_request:
    branches: [main, master]

env:
  NEW_HSTREAM_IMAGE: new_hstream_image

jobs:
  pre-build:
    runs-on: ubuntu-latest
    name: prepare pre-build environment for tests
    outputs:
      ghc: ${{ steps.parser.outputs.ghc }}
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: "recursive"

      - id: parser
        run: |
          pkgcabal="hstream/hstream.cabal"
          GHCS=$(cat ${pkgcabal} | grep tested-with | python3 -c 'import sys, re, json; print(re.findall(r"(\d+\.\d+\.\d+)", sys.stdin.read()))')
          echo "Set ghc versions: $GHCS..."
          echo "ghc=$GHCS" >> $GITHUB_OUTPUT

      - name: run stylish-haskell
        run: |
          # install stylish-haskell
          PACKAGE=stylish-haskell
          URL=$(\
            curl --silent https://api.github.com/repos/haskell/$PACKAGE/releases/latest \
            | grep "browser_download_url.*linux-x86_64\.tar\.gz" \
            | cut -d ':' -f 2,3 \
            | tr -d \" \
          )
          VERSION=$(echo $URL | sed -e 's/.*-\(v[\.0-9]\+-linux-x86_64\)\.tar\.gz/\1/')
          TEMP=$(mktemp --directory)
          curl --progress-bar --location -o$TEMP/$PACKAGE.tar.gz $URL
          tar -xzf $TEMP/$PACKAGE.tar.gz -C$TEMP
          chmod +x $TEMP/$PACKAGE-$VERSION/$PACKAGE
          # check all sources
          echo "Run script/format.sh with latest stylish-haskell..."
          FORMATER_BIN=$TEMP/$PACKAGE-$VERSION/$PACKAGE bash script/format.sh ci && git diff-index --exit-code HEAD

  build-and-test:
    needs: pre-build
    runs-on: ubuntu-latest
    name: GHC-${{ matrix.ghc }}
    strategy:
      fail-fast: false
      matrix:
        ghc: ${{ fromJson(needs.pre-build.outputs.ghc) }}
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: "recursive"

      - name: set env
        run: |
          docker pull docker.io/hstreamdb/haskell:${{ matrix.ghc }}
          echo "CABAL=python3 script/dev-tools cabal --check --no-interactive -i docker.io/hstreamdb/haskell:${{ matrix.ghc }}" >> $GITHUB_ENV
          echo "SHELL=python3 script/dev-tools shell --check --no-interactive -i docker.io/hstreamdb/haskell:${{ matrix.ghc }}" >> $GITHUB_ENV

      - name: start required services
        run: python3 script/dev-tools start-services

      - name: cabal update
        run: ${{ env.CABAL }} update

      - name: cabal freeze
        run: ${{ env.CABAL }} freeze

      - name: cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cabal/packages
            ~/.cabal/store
            dist-newstyle
          key: ${{ runner.os }}-${{ matrix.ghc }}-v2-${{ hashFiles('**/*.cabal') }}-${{ hashFiles('**/cabal.project*') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.ghc }}-v2

      # Since we use the upgraded version of z-data and z-io, this should resolve the problem.
      #
      # We remove these caches because there is an unknown reason that will cause ci to fail without any error message.
      #- name: remove all Z related builds
      #  run: find ~/.cabal/store/ -maxdepth 2 -type d -name "Z*" -o -name "zoo*" | xargs rm -rf

      - name: build
        run: |
          ${{ env.CABAL }} update
          ${{ env.SHELL }} "'make clean'"
          ${{ env.SHELL }} make
          ${{ env.CABAL }} -- build --enable-tests --enable-benchmarks all
          ${{ env.CABAL }} -- install hstream

      - name: start hstream server
        run: |
          export CONTAINER_NAME="test-hstream-server"
          export IMAGE="docker.io/hstreamdb/haskell:${{ matrix.ghc }}"
          export EXTRA_OPTS="--check --no-interactive --detach"
          export COMMAND=" "
          export EXE=$(find dist-newstyle -name "hstream-server" -type f)
          ./script/start-server.sh
          sleep 5
          docker logs --tail 100 $CONTAINER_NAME

      - name: test
        run: |
          ${{ env.CABAL }} -- test --test-show-details=direct all

      # Due to an [cabal bug](https://github.com/haskell/cabal/issues/7423),
      # `cabal check` will emit a warning even if the `-O2` option is just
      # an flag. This is disabled until the problem is fixed.
      #- name: check
      #  run: |
      #    python3 script/dev-tools cabal --check --no-interactive -i docker.io/hstreamdb/haskell:${{ matrix.ghc }} -- sdist all

      #    # unfortunately, there is no `cabal check all`
      #    #log_info "Run all cabal check..."
      #    # Note that we ignore hstream-store package to run cabal check, because there
      #    # is an unexpected warning:
      #    #   ...
      #    #   Warning: 'cpp-options': -std=c++17 is not portable C-preprocessor flag
      #    #   Warning: Hackage would reject this package.
      #    for dir in hstream-sql hstream-processing hstream; do
      #      python3 script/dev-tools shell --check --no-interactive -i docker.io/hstreamdb/haskell:${{ matrix.ghc }} "'cd $dir && cabal check'"
      #    done

      # TODO
      #- name: haddock
      #    python3 script/dev-tools cabal --check --no-interactive -i docker.io/hstreamdb/haskell:${{ matrix.ghc }} -- haddock haddock --enable-documentation --haddock-for-hackage all

      # -------------------------------------------------------------------------------

      - name: stop all started services
        run: docker rm -f $(docker ps -a -q)

      - name: quick build new hstream image
        run: |
          mkdir -p ~/data

          python3 script/dev-tools quick-build-dev-image \
            --builder-image docker.io/hstreamdb/haskell:${{ matrix.ghc }} \
            -t $NEW_HSTREAM_IMAGE

          docker save -o ~/data/new_hstream_image.tar $NEW_HSTREAM_IMAGE

      - uses: actions/upload-artifact@v3
        with:
          name: image-testing
          path: ~/data/new_hstream_image.tar
          retention-days: 5

  integration-tests:
    needs: build-and-test
    runs-on: ubuntu-latest
    name: integration-tests
    strategy:
      fail-fast: false

    steps:
      - name: retrieve saved docker image
        uses: actions/download-artifact@v3
        with:
          name: image-testing
          path: ~/data

      - name: docker load
        run: docker load -i ~/data/new_hstream_image.tar

      - name: fetch integration tests source code
        uses: actions/checkout@v3
        with:
          repository: "hstreamdb/integration-tests"
          submodules: "recursive"
          path: integration-tests

      - uses: actions/setup-java@v2
        with:
          distribution: "adopt"
          java-version: 11
          cache: "gradle"

      - uses: gradle/wrapper-validation-action@v1

      - name: run integration tests
        run: |
          cd integration-tests
          export HSTREAM_IMAGE_NAME=$NEW_HSTREAM_IMAGE
          ./gradlew test --info --fail-fast -Dtag='basicTest'

      - name: collect tests reports
        if: ${{ success() }} || ${{ failure() }}
        run: |
          rm -rf ci_artifact && mkdir ci_artifact
          mv integration-tests/.logs ci_artifact/logs
          mv integration-tests/app/build/reports ci_artifact/reports

      - name: upload tests-reports
        uses: actions/upload-artifact@v3
        if: ${{ success() }} || ${{ failure() }}
        with:
          name: integration-tests-reports
          path: ci_artifact
          retention-days: 7

  integration-tests-rqlite:
    needs: build-and-test
    runs-on: ubuntu-latest
    name: integration-tests-rqlite
    strategy:
      fail-fast: false

    steps:
      - name: retrieve saved docker image
        uses: actions/download-artifact@v3
        with:
          name: image-testing
          path: ~/data

      - name: docker load
        run: docker load -i ~/data/new_hstream_image.tar

      - name: fetch integration tests source code
        uses: actions/checkout@v3
        with:
          repository: "hstreamdb/integration-tests"
          submodules: "recursive"
          path: integration-tests

      - uses: actions/setup-java@v2
        with:
          distribution: "adopt"
          java-version: 11
          cache: "gradle"

      - uses: gradle/wrapper-validation-action@v1

      - name: run integration tests
        run: |
          cd integration-tests
          export HSTREAM_IMAGE_NAME=$NEW_HSTREAM_IMAGE
          export HSTREAM_META_STORE=RQLITE
          ./gradlew test --info --fail-fast -Dtag='basicTest'

      - name: collect tests reports
        if: ${{ success() }} || ${{ failure() }}
        run: |
          rm -rf ci_artifact && mkdir ci_artifact
          mv integration-tests/.logs ci_artifact/logs
          mv integration-tests/app/build/reports ci_artifact/reports

      - name: upload tests-reports
        uses: actions/upload-artifact@v3
        if: ${{ success() }} || ${{ failure() }}
        with:
          name: integration-tests-rqlite-reports
          path: ci_artifact
          retention-days: 7

  distributed-tests:
    needs: build-and-test
    runs-on: ubuntu-latest
    name: distributed-tests
    strategy:
      fail-fast: false

    steps:
      - name: retrieve saved docker image
        uses: actions/download-artifact@v3
        with:
          name: image-testing
          path: ~/data

      - name: docker load
        run: docker load -i ~/data/new_hstream_image.tar

      - name: fetch distributed tests source code
        uses: actions/checkout@v3
        with:
          repository: "hstreamdb/distributed-tests"
          submodules: "recursive"
          path: distributed-tests

      - uses: actions/setup-java@v3
        with:
          distribution: "adopt"
          java-version: 11
          cache: "gradle"

      # https://github.com/gradle/wrapper-validation-action/issues/66
      - uses: gradle/wrapper-validation-action@v1

      - name: run distributed tests
        run: |
          cd distributed-tests
          export HSTREAM_IMAGE_NAME=$NEW_HSTREAM_IMAGE
          ./gradlew test --info --fail-fast

      - name: collect tests reports
        if: ${{ success() }} || ${{ failure() }}
        run: |
          rm -rf ci_artifact && mkdir ci_artifact
          mv distributed-tests/.logs ci_artifact/logs
          mv distributed-tests/app/build/reports ci_artifact/reports

      - name: upload tests-reports
        uses: actions/upload-artifact@v3
        if: ${{ success() }} || ${{ failure() }}
        with:
          name: distributed-tests-reports
          path: ci_artifact
          retention-days: 7

  hstream-io-tests:
    needs: build-and-test
    runs-on: ubuntu-latest
    name: hstream-io-tests
    strategy:
      fail-fast: false

    steps:
      - name: retrieve saved docker image
        uses: actions/download-artifact@v3
        with:
          name: image-testing
          path: ~/data

      - name: docker load
        run: docker load -i ~/data/new_hstream_image.tar

      - name: fetch hstream io tests source code
        uses: actions/checkout@v3
        with:
          repository: "hstreamdb/hstream-connectors"
          submodules: "recursive"
          path: hstream-connectors

      - uses: actions/setup-java@v3
        with:
          distribution: "adopt"
          java-version: 11
          cache: "gradle"

      - uses: gradle/wrapper-validation-action@v1

      - name: publish local java-toolkit
        working-directory: ./hstream-connectors/java-toolkit
        run: ./gradlew publishToMavenLocal -PdisableSigning --info

      - name: build images
        run: |
          cd hstream-connectors/source-debezium
          ./gradlew buildImages
          cd ../sink-jdbc
          ./gradlew buildImages
          cd ../sink-mongodb
          ./gradlew buildImages

      - name: run hstream io tests
        run: |
          cd hstream-connectors/integration_tests
          export HSTREAM_IMAGE_NAME=$NEW_HSTREAM_IMAGE
          export HSTREAM_IO_USE_DEFAULT_IMAGES=true
          ./gradlew test --info --fail-fast

      - name: collect tests reports
        if: ${{ success() }} || ${{ failure() }}
        run: |
          rm -rf ci_artifact && mkdir ci_artifact
          mv hstream-connectors/integration_tests/.logs ci_artifact/logs
          mv hstream-connectors/integration_tests/app/build/reports ci_artifact/reports
          export U=$(id -u); export G=$(id -g); sudo chown -R $U:$G /tmp/io
          mv /tmp/io/tasks ci_artifact/tasks

      - name: upload tests-reports
        uses: actions/upload-artifact@v3
        if: ${{ success() }} || ${{ failure() }}
        with:
          name: hstream-io-logs
          path: ci_artifact
          retention-days: 7

  deploy-k8s:
    # disabled due to a lack of hardware resources of the github action
    if: false
    needs: build-and-test
    runs-on: ubuntu-latest
    name: deploy to minikube
    strategy:
      fail-fast: true

    steps:
      - name: Start minikube
        uses: medyagh/setup-minikube@master

      - name: Try the cluster !
        run: kubectl get pods -A

      - name: Retrieve saved docker image
        uses: actions/download-artifact@v3
        with:
          name: image-testing
          path: ~/data

      - name: Load image
        run: |
          export SHELL=/bin/bash
          eval $(minikube -p minikube docker-env)
          docker load -i ~/data/new_hstream_image.tar
          docker tag $NEW_HSTREAM_IMAGE hstreamdb/hstream
          echo -n "verifying images:"
          docker images

      - uses: actions/checkout@v3
      - name: Deploy to minikube by helm
        run: |
          cd deploy/chart/hstream
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update
          helm dependency build .
          helm install my-hstream .

      - name: Waiting for cluster ready
        run: |
          timeout=600    # seconds
          until ( \
              kubectl exec -it my-hstream-0 -- hadmin server status |grep "100.*Running" && \
              kubectl exec -it my-hstream-0 -- hadmin server status |grep "101.*Running" && \
              kubectl exec -it my-hstream-0 -- hadmin server status |grep "102.*Running"
              ) >/dev/null 2>&1;
          do
            >&2 echo "Waiting for cluster ready ..."
            kubectl get pods
            sleep 10
            timeout=$((timeout - 10))
            if [ $timeout -le 0 ]; then
              echo "Timeout!" && \
              kubectl logs --tail 100 my-hstream-0 ; \
              kubectl logs --tail 100 my-hstream-1 ; \
              kubectl logs --tail 100 my-hstream-2 ; \
              kubectl exec -it my-hstream-0 -- hadmin server status ; \
              exit 1;
            fi
          done

          sleep 2
          kubectl exec -it my-hstream-0 -- hadmin store --host my-hstream-logdevice-admin-server status
          kubectl exec -it my-hstream-0 -- hadmin server status

      - name: Fetch bench source code
        uses: actions/checkout@v3
        with:
          repository: "hstreamdb/bench"
          submodules: "recursive"
          path: a_bench

      - name: Run simple appends
        run: |
          eval $(minikube -p minikube docker-env)
          cd a_bench
          echo -e "FROM openjdk:11\nCOPY . /srv\nWORKDIR /srv" | docker build -t tmp_bench -f - .
          ADDR=$(kubectl get pods my-hstream-0 --template '{{.status.podIP}}')
          docker run -t --rm tmp_bench \
            ./gradlew writeBench --args="\
               --bench-time=30 \
               --warmup=1 \
               --service-url=$ADDR:6570 \
               --thread-count=1 \
               --stream-count=2 \
               --shard-count=1 \
               --stream-backlog-duration=60 \
               --stream-replication-factor=1 \
               --record-size=1024 \
               --batch-bytes-limit=2048 \
               --batch-age-limit=500 \
               --rate-limit=100 \
               --total-bytes-limit=8192"
